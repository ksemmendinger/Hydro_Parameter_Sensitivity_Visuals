{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 0: Fall Creek Watershed, NY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads, graphs and performs sensitivity analysis for observations, parameters and models from 24,000 SWMM model runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows us to run R scripts in the Python jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the objective functions for the SWMM simulated streamflow, we use the hydroGOF package in R [(Documentation)](https://cran.r-project.org/web/packages/hydroGOF/index.html). For the SWMM streamflow simulations in the Fall Creek, NY watershed, we calculated mean error, mean absolute error, mean squared error, Nase-Sutcliffe efficiency, percent bias, and root mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in read.table(file = file, header = header, sep = sep, quote = quote,  : \n",
      "  invalid 'row.names' specification\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "# %load CaseStudy0_OFs.R\n",
    "# Case Study 0: Fall Creek, NY\n",
    "\n",
    "# This script calculates six objective functions from 24,000 SWMM model runs and USGS streamgage \n",
    "# data using the hydroGOF package (https://cran.r-project.org/web/packages/hydroGOF/hydroGOF.pdf)\n",
    "\n",
    "library(dplyr)\n",
    "library(hydroGOF)\n",
    "\n",
    "# load in observation, simulation, and parameter sets\n",
    "obs <- read.csv(\"input/observation_ts.csv\", header = TRUE)\n",
    "  # \"time_steps\" row, \"index\" and \"value\" columns \n",
    "sim <- read.csv(\"input/simulation_ts.csv\", header = TRUE)\n",
    "  # \"model_runs\" rows, \"time_steps\" columns\n",
    "pars <- read.csv(\"input/params.csv\", header = FALSE)\n",
    "  # \"model_runs\" rows, \"num_pars\" columns\n",
    "timestamps <- read.csv(\"input/timestamps.csv\", header = TRUE)\n",
    "\n",
    "model_runs <- nrow(sim)\n",
    "time_steps <- ncol(sim)\n",
    "num_pars <- ncol(pars)\n",
    "\n",
    "mean_error <- array(NA, model_runs)\n",
    "mean_abs_error <- array(NA, model_runs)\n",
    "mean_sq_error <- array(NA, model_runs)\n",
    "root_mse <- array(NA, model_runs)\n",
    "p_bias <- array(NA, model_runs)\n",
    "nse <- array(NA, model_runs)\n",
    "\n",
    "for (i in 1:model_runs) {\n",
    "\n",
    "  print(i)\n",
    "\n",
    "  mean_error[i] <- me(sim = as.numeric(sim[i, 2:time_steps]), obs = as.numeric(obs[, 2]))\n",
    "  mean_abs_error[i] <- mae(sim = as.numeric(sim[i, 2:time_steps]), obs = as.numeric(obs[, 2]))\n",
    "  mean_sq_error[i] <- mse(sim = as.numeric(sim[i, 2:time_steps]), obs = as.numeric(obs[, 2]))\n",
    "  root_mse[i] <- rmse(sim = as.numeric(sim[i, 2:time_steps]), obs = as.numeric(obs[, 2]))\n",
    "  p_bias[i] <- pbias(sim = as.numeric(sim[i, 2:time_steps]), obs = as.numeric(obs[, 2]))\n",
    "  nse[i] <- NSE(sim = as.numeric(sim[i, 2:time_steps]), obs = as.numeric(obs[, 2]))\n",
    "\n",
    "}\n",
    "\n",
    "OF <- as.data.frame(mean_error) %>%\n",
    "  setNames(\"me\") %>%\n",
    "  dplyr:: mutate(mae = mean_abs_error,\n",
    "                 mse = mean_sq_error,\n",
    "                 rmse = root_mse,\n",
    "                 pbias = p_bias,\n",
    "                 nse = nse)\n",
    "\n",
    "write.table(OF, \"input/OF_values.txt\", sep = \" \", row.names = FALSE, col.names = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# observations for objective functions\n",
    "#df_obs = pd.read_csv('input/observation_ts.csv')\n",
    "\n",
    "# parameters for the 24,000 model runs\n",
    "df_parms = pd.read_csv('input/params.csv',header=None)\n",
    "df_parms.columns = ['w', 'n_imperv', 'n_perv', 's_imperv', 's_perv', 'k_sat', 'per_routed', 'cmelt', 'Tb', 'A1', 'B1']\n",
    "\n",
    "# model results\n",
    "#df_model = pd.read_csv('input/simulation_ts.csv')\n",
    "\n",
    "# calculated objective functions\n",
    "df_OFs = pd.read_csv('input/OF_values.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Graph Observed and Modeled Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add R code here for timeseries plotting here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Approximate Bayesian Calculation\n",
    "Approximate Bayesian computation (ABC) represents the combination of model parameter values that maximize the probability of representing the observed data. ABC bypasses the evaluation of the likelihood function by approximating the likelihood function by using simulations compared to the observed data. For more information on ABC, see Engeland and Gottschalk (2002), Neuman (2003), Sunnaker et al. (2013) etc. \n",
    "\n",
    "The steps and requirements for approximate Bayesian calculation are: 1) Observed data has a known mean and standard deviation and the user defines a summary statistic (i.e. objective function) 2) Assume you don’t know anything about the parameters, so assume a uniform prior interval [0,1]. 3) A total of n parameters are drawn from prior, the model is simulated for each of the parameter points , which results in n sequences of simulated data. 4) Calculate the summary statistic for each sequence of simulated data 5) Calculate distance between observed and simulated transition frequencies for all parameter points. Specify some tolerance  and “keep” parameter points smaller than or equal to the summary statistic as approximate samples from the posterior.\n",
    "\n",
    "For the python script below, specify the number of model runs, tolerance of the objective functions, number of histogram bins and the figure colors. Here we used pre-defined objective functions, but the code can be modified to calculate a variety of objective functions. The plots produced are histograms of the various parameters illustrating the difference between original modeled output and the ABC constrained parameter sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load approx_bayes_calc_of_defined.py \n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Created on Mon Jul  8 12:57:45 2019\n",
    "\n",
    "@author: catiefinkenbiner\n",
    "\"\"\"\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''\n",
    "Approximate Baysian Calculation requires:\n",
    "    1) observation dataset (df_obs)\n",
    "    2) parameter sets (df_parms)\n",
    "    3) model output (df_model)\n",
    "    4) objective functions (df_OFs)\n",
    "    5) tolerance\n",
    "    6) number of model runs\n",
    "'''\n",
    "\n",
    "def approx_bayes_calc_OF(parms,OFs,simulations):\n",
    "    keep_nse = []; keep_pbias = []; keep_rmse = []\n",
    "    for i in np.arange((simulations)):\n",
    "        # User can redefine tolerance and OF here\n",
    "        if tolerance_rmse < OFs.iloc[i,3]:\n",
    "            keep_rmse.append(parms.loc[i])\n",
    "            \n",
    "        if np.absolute(OFs.iloc[i,4]) < tolerance_pbias:\n",
    "            keep_pbias.append(parms.loc[i])\n",
    "            \n",
    "        if OFs.iloc[i,5] >= tolerance_nse:\n",
    "            keep_nse.append(parms.loc[i])        \n",
    "    return keep_nse,keep_pbias,keep_rmse\n",
    "\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "def make_histograms(df_parms,bayes_approx,bins,alpha,cc1,cc2,parameters,metric):\n",
    "    plt.figure(figsize=(12,12))\n",
    "    for col in np.arange(1,((df_parms.iloc[0,:]).size)):\n",
    "        plt.subplot(4,3,col)\n",
    "        ax = df_parms.iloc[:,col].plot.hist(bins=bins,alpha=alpha,color=cc1)    \n",
    "        ax = bayes_approx.iloc[:,col].plot.hist(bins=bins,alpha=alpha,color=cc2)\n",
    "        ax.set_xlabel(str(parameters[col]))    \n",
    "    plt.legend(['Output','ABC'],fancybox=True)\n",
    "    plt.tight_layout() \n",
    "    plt.savefig(metric+'.png',dpi=300)\n",
    "\n",
    "def runABC(df_parms,df_OFs,runs,bins,color1,color2):\n",
    "    # models with objective functions within tolerance thresholds\n",
    "    results_nse,results_pbias,results_rmse = np.array(approx_bayes_calc_OF(df_parms,df_OFs,runs))\n",
    "    \n",
    "    # saves models with objective functions within tolerance thresholds\n",
    "    bayes_approx_nse = pd.DataFrame(results_nse,columns=None)\n",
    "    bayes_approx_pbias = pd.DataFrame(results_pbias,columns=None)\n",
    "    bayes_approx_rmse = pd.DataFrame(results_rmse,columns=None)\n",
    "    parameters = list(df_parms.columns.values)\n",
    "    \n",
    "    # print ABC results and make figures\n",
    "    print('precent of models with NSE >= to',str(tolerance_nse),'are:',str(len(results_nse)/runs),'%')\n",
    "    make_histograms(df_parms,bayes_approx_nse,bins,0.5,color1,color2,parameters,'NSE')\n",
    "    print('precent of models with',str(-tolerance_pbias),'<= p-bias >=',str(tolerance_pbias),'are:',str(len(results_pbias)/runs),'%')\n",
    "    make_histograms(df_parms,bayes_approx_pbias,bins,0.5,color1,color3,parameters,'pbias')\n",
    "    print('precent of models with RMSE < to',str(tolerance_rmse),'are:',str(len(results_rmse)/runs),'%')\n",
    "    make_histograms(df_parms,bayes_approx_rmse,bins,0.5,color1,color4,parameters,'RMSE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify tolerance for objective functions (OF)\n",
    "tolerance_rmse = 6.0   # OF < tolerance\n",
    "tolerance_pbias = 15.0 # -tolerance < OF > tolerance\n",
    "tolerance_nse = 0.0  # OF >= tolerance\n",
    "\n",
    "runs = 24000 # specify number of model runs\n",
    "bins = 100   # specify number of histogram bins\n",
    "color1 = 'b' # color of original model output\n",
    "color2 = 'k' # color of 1st ABC applied to OF (NSE)\n",
    "color3 = 'r' # color of 2nd ABC applied to OF (p-bias)\n",
    "color4 = 'g' # color of 3rd ABC applied to OF (RMSE)\n",
    "\n",
    "# Runs function that evaluates models outputs with approximate Bayesian calculations\n",
    "runABC(df_parms,df_OFs,runs,bins,color1,color2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sensitivity Analysis\n",
    "Python modules to conduct three sensitivity analyses are included in this jupyter notebook.\n",
    "\n",
    "Sobol sensitivity\n",
    "\n",
    "Delta sensitivity\n",
    "\n",
    "OLS sensitivity\n",
    "\n",
    "write some stuff about this ...\n",
    "\n",
    "\n",
    "Approximate Bayesian computation (ABC) represents the combination of model parameter values that maximize the probability of representing the observed data. ABC bypasses the evaluation of the likelihood function by approximating the likelihood function by using simulations compared to the observed data. For more information on ABC, see Engeland and Gottschalk (2002), Neuman (2003), Sunnaker et al. (2013) etc. \n",
    "\n",
    "The steps and requirements for approximate Bayesian calculation are: 1) Observed data has a known mean and standard deviation and the user defines a summary statistic (i.e. objective function) 2) Assume you don’t know anything about the parameters, so assume a uniform prior interval [0,1]. 3) A total of n parameters are drawn from prior, the model is simulated for each of the parameter points , which results in n sequences of simulated data. 4) Calculate the summary statistic for each sequence of simulated data 5) Calculate distance between observed and simulated transition frequencies for all parameter points. Specify some tolerance  and “keep” parameter points smaller than or equal to the summary statistic as approximate samples from the posterior.\n",
    "\n",
    "For the python script below, specify the number of model runs, tolerance of the objective functions, number of histogram bins and the figure colors. Here we used pre-defined objective functions, but the code can be modified to calculate a variety of objective functions. The plots produced are histograms of the various parameters illustrating the difference between original modeled output and the ABC constrained parameter sets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load CaseStudy0_SI_RCPs.py\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Created on Wed Jul 10 12:56:56 2019\n",
    "\n",
    "@author: kylasemmendinger\n",
    "\"\"\"\n",
    "# import python libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# back out a directory to load python functions from \"Scripts\" folder\n",
    "org_dir_name = os.path.dirname(os.path.realpath('CaseStudy0_SI_RCPs.py'))\n",
    "parent_dir_name = os.path.dirname(os.path.dirname(os.path.realpath('CaseStudy0_SI_RCPs.py')))\n",
    "os.chdir(parent_dir_name + \"/Scripts\")\n",
    "\n",
    "# load python functions from ‘Scripts’ folder\n",
    "import delta\n",
    "import sobol\n",
    "import ols\n",
    "import radial_conv_plots\n",
    "\n",
    "# move back into case study 0 folder\n",
    "os.chdir(org_dir_name)\n",
    "\n",
    "# Define the model inputs\n",
    "problem = {\n",
    "    'num_vars': 11,\n",
    "    'names': ['w', 'n_imperv', 'n_perv', 's_imperv', 's_perv', 'k_sat', 'per_routed', 'cmelt', 'Tb', 'A1', 'B1'],\n",
    "    'bounds': [[500, 1500], # meters\n",
    "               [0.01, 0.2],\n",
    "               [0.01, 0.2],\n",
    "               [0, 10],\n",
    "               [0, 10],\n",
    "               [0.01, 10],\n",
    "               [0, 100],\n",
    "               [0, 4],\n",
    "               [-3, 3],\n",
    "               [0.0001, 0.01],\n",
    "               [1, 3]]\n",
    "}\n",
    "\n",
    "# load in model simulations, observation data, parameter sets (Saltelli sampled), timestamps, and objective function values\n",
    "sim = pd.read_csv(\"input/simulation_ts.csv\", index_col = 0)\n",
    "obs = pd.read_csv(\"input/observation_ts.csv\")\n",
    "pars = pd.read_csv(\"input/params.csv\", header = None)\n",
    "timestamps = pd.read_csv(\"input/timestamps.csv\")\n",
    "OF = pd.read_csv(\"input/OF_values.csv\")\n",
    "\n",
    "# save the parameter names\n",
    "param_names = problem['names']\n",
    "\n",
    "# calculate Sobol first-, second-, and total order indices --> MUST BE BASED ON SALTELLI SAMPLING SCHEME\n",
    "results_SI = []\n",
    "results_SI = sobol.objective_function_sobol(problem, OF)\n",
    "\n",
    "# create radial convergence plots based on results_SI\n",
    "radial_conv_plots.radial_conv_plots(problem, results_SI, OF)\n",
    "\n",
    "# calculate delta indices and sobol first-order indices\n",
    "results_delta = []\n",
    "results_delta = delta.objective_function_delta(problem, pars, OF)\n",
    "\n",
    "# calculate R^2 from OLS regression\n",
    "results_R2 = []\n",
    "results_R2 = ols.objective_function_OLS(OF, pars, param_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Visualizations\n",
    "\n",
    "Talk about some visualization techniques here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# %load CaseStudy0_Visuals.R\n",
    "\n",
    "# This script loads in data from Sobol, Delta, and OLS sensitivity analyses calculated in\n",
    "# Python script for Case Study 0: Fall Creek, NY.\n",
    "\n",
    "library(dplyr)\n",
    "\n",
    "# load in observation, simulation, and parameter sets\n",
    "obs <- read.csv(\"input/observation_ts.csv\", header = TRUE)\n",
    "  # \"time_steps\" row, 1 column of values\n",
    "\n",
    "sim <- read.csv(\"input/simulation_ts.csv\", header = TRUE) %>%\n",
    "  dplyr::select(-1)\n",
    "  # \"model_runs\" rows, \"time_steps\" columns\n",
    "\n",
    "pars <- read.csv(\"input/params.csv\", header = FALSE)\n",
    "  # \"model_runs\" rows, \"num_pars\" columns\n",
    "\n",
    "timestamps <- read.csv(\"input/timestamps.csv\", header = TRUE)\n",
    "  # \"time_steps\" row, 1 column of values\n",
    "\n",
    "OF <- read.csv(\"input/OF_values.csv\", header = TRUE)\n",
    "  # \"model_runs\" rows, \"num_OF\" columns\n",
    "\n",
    "# save names of objective functions and parameters\n",
    "OF_names <- colnames(OF)\n",
    "param_names <- c(\"w\", \"n_imperv\", \"n_perv\", \"s_imperv\", \"s_perv\", \"k_sat\", \n",
    "                 \"per_routed\", \"cmelt\", \"Tb\", \"A1\", \"B1\")\n",
    "\n",
    "# clean up data\n",
    "obs <- array(obs[, 2])\n",
    "timestamps <- array(timestamps[, 2])\n",
    "colnames(pars) <- param_names\n",
    "\n",
    "# set variables of number of model runs, time steps, and number of parameters\n",
    "model_runs <- nrow(sim)\n",
    "time_steps <- ncol(sim)\n",
    "num_pars <- ncol(pars)\n",
    "num_OF <- ncol(OF)\n",
    "\n",
    "# load in results from delta, sobol, and ols sensitivity analyses (calculated in python script)\n",
    "source(\"../Scripts/python_to_r_results.R\")\n",
    "results_sobol <- python_to_r_results(data_type = \"sobol\", param_names, OF_names)\n",
    "results_delta <- python_to_r_results(data_type = \"delta\", param_names, OF_names)\n",
    "results_ols <- python_to_r_results(data_type = \"ols\", param_names, OF_names)\n",
    "\n",
    "# scatter plots of objective functions versus parameter values\n",
    "source(\"../Scripts/scatterplots.R\")\n",
    "for (i in 1:num_OF) {\n",
    "  \n",
    "  # subset by objective function, i\n",
    "  objective_fun <- OF[, i]\n",
    "\n",
    "  # create scatterplots of all parameters versus objective function, i\n",
    "  par_OF_scatter(params = pars, objective_fun, OF_name = colnames(OF)[i])\n",
    "  \n",
    "}\n",
    "\n",
    "# portrait plots of objective functions versus parameter values\n",
    "source(\"../Scripts/portrait_plots.R\")\n",
    "portrait_plot(results_sobol)\n",
    "portrait_plot(results_delta)\n",
    "portrait_plot(results_ols)\n",
    "\n",
    "# spiders plots of objective functions versus parameter values\n",
    "source(\"../Scripts/spider_plots.R\")\n",
    "spiderplot(results_sobol)\n",
    "spiderplot(results_delta)\n",
    "spiderplot(results_ols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XX. Conclusion\n",
    "\n",
    "We did awesome stuff and this is how we feel about it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XX. References\n",
    "- Engeland, K., Gottschalk L. Bayesian estimation of parameters in regional hydrological model, Hydrol. Earth Sys. Sci., **2002**, *6*(5), 883-898. https://doi.org/10.5194/hess-6-883-2002\n",
    "- Neuman, S. Maximum likelihood Bayesian averaging of uncertain model predictions, Stoch. Environ. Res. Risk Assess. **2003** *17*, 291. https://doi.org/10.1007/s00477-003-0151-7\n",
    "- Sunnåker M., Busetto A.G., Numminen E., Corander J., Foll M., Dessimoz C. Approximate Bayesian Computation, PLoS Comput. Biol. **2013** *9*(1): e1002803. https://doi.org/10.1371/journal.pcbi.1002803\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
