{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWMM Simulated Streamflow in Fall Creek, NY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input files for the HBV, SWMM, and TOPMODEL case studies are available [here](https://drive.google.com/drive/folders/1p96I1m88nDhiwVyOoEX0ywuL5g0oBNuk?usp=sharing). To run the below scripts, copy these files into the input folder within the directory of the case study. Note: The figures generated from our workflow have generic axis labels for adaptability and use across dissimilar hydrologic modeling applications. This jupyter notebook will also re-create some of the published figures from the JAWRA manuscript (figures are located in folder labeled 'JAWRA_Figures').\n",
    "\n",
    "The Fall Creek watershed is a 325 km<sup>2</sup> basin, located near Ithaca, New York. To complete Sobol, delta, and OLS sensitivity analyses on SWMM simulated streamflow to input parameters, we employed the Saltelli sampling scheme (described in more detail in Section 3) to create 24,000 unique parameter sets. The code is available in the \"Sampling.py\" script. Each parameter set was run through the Storm Water Management Model (SWMM) from January 1, 2013 through June 30, 2013, and the time series of simulated streamflow was extracted. Simulated streamflow was compared to USGS stream gauge data (waterdata.usgs.gov). Six objective functions were calculated and used as model performance metrics using the R “hydroGOF” package: mean absolute error (MAE), mean error (ME), mean squared error (MSE), Nash-Sutcliff efficiency (NSE), percent bias (pbias), and root mean squared error (RMSE).\n",
    "\n",
    "This jupyter notebook has code cells to:\n",
    "1. Load data for use in R and Python scripts\n",
    "2. Calculate objective function values (i.e. performance metrics)\n",
    "3. Create a historical time series and magnitude percentile plots for simulated data\n",
    "4. Generate a priori and a posteriori parameter distribution plots via Approximate Bayesian Computation\n",
    "5. Compute Sobol first-order, Sobol second-order, Sobol total-order, delta, and OLS sensitivity indices\n",
    "6. Produce portrait, scatter, and spider plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete and visualize a comprehensive sensitivity analysis on the SWMM simulations, we use packages from both R and Python. This command allows us to run R scripts in the Python jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the objective functions for the SWMM simulated streamflow, we use the [hydroGOF](https://cran.r-project.org/web/packages/hydroGOF/hydroGOF.pdf) package in R. For the SWMM streamflow simulations in the Fall Creek, NY watershed, we calculate mean error, mean absolute error, mean squared error, Nase-Sutcliffe efficiency, percent bias, and root mean squared error. The objective function evaluations are saved in the \"input/\" folder to be loaded into the sensitivity analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R \n",
    "# this rpy2 'Rmagic' command allows to run the entire cell block as R code\n",
    "\n",
    "# load in the R script that calculates six objective functions on SWMM model simulations versus USGS streamgage data\n",
    "# # %load Calculate_Objective_Functions.R\n",
    "\n",
    "library(dplyr)\n",
    "library(hydroGOF)\n",
    "library(readxl)\n",
    "\n",
    "# load in observation, simulation, and parameter sets\n",
    "obs <- read.csv(\"input/observation_ts.csv\", header = TRUE)\n",
    "  # \"time_steps\" row, \"index\" and \"value\" columns \n",
    "sim <- read_xlsx(\"input/simulation_ts.xlsx\") %>%\n",
    "  dplyr::select(-1)\n",
    "  # \"model_runs\" rows, \"time_steps\" columns\n",
    "\n",
    "model_runs <- nrow(sim)\n",
    "time_steps <- ncol(sim)\n",
    "\n",
    "mean_error <- array(NA, model_runs)\n",
    "mean_abs_error <- array(NA, model_runs)\n",
    "mean_sq_error <- array(NA, model_runs)\n",
    "root_mse <- array(NA, model_runs)\n",
    "p_bias <- array(NA, model_runs)\n",
    "nse <- array(NA, model_runs)\n",
    "\n",
    "for (i in 1:model_runs) {\n",
    "\n",
    "  print(i)\n",
    "\n",
    "  mean_error[i] <- me(sim = as.numeric(sim[i, 1:time_steps]), obs = as.numeric(obs[, 2]))\n",
    "  mean_abs_error[i] <- mae(sim = as.numeric(sim[i, 1:time_steps]), obs = as.numeric(obs[, 2]))\n",
    "  mean_sq_error[i] <- mse(sim = as.numeric(sim[i, 1:time_steps]), obs = as.numeric(obs[, 2]))\n",
    "  root_mse[i] <- rmse(sim = as.numeric(sim[i, 1:time_steps]), obs = as.numeric(obs[, 2]))\n",
    "  p_bias[i] <- pbias(sim = as.numeric(sim[i, 1:time_steps]), obs = as.numeric(obs[, 2]))\n",
    "  nse[i] <- NSE(sim = as.numeric(sim[i, 1:time_steps]), obs = as.numeric(obs[, 2]))\n",
    "\n",
    "}\n",
    "\n",
    "OF <- as.data.frame(mean_error) %>%\n",
    "  setNames(\"me\") %>%\n",
    "  dplyr:: mutate(mae = mean_abs_error,\n",
    "                 mse = mean_sq_error,\n",
    "                 rmse = root_mse,\n",
    "                 pbias = p_bias,\n",
    "                 nse = nse)\n",
    "\n",
    "write.table(OF, \"/input/OF_values.txt\", sep = \" \",\n",
    "            row.names = FALSE, col.names = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the model simulation data, observation/truth data, parameter sets, time stamps, and objective function values into Python as data frames using the pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#sim = pd.read_excel(\"input/simulation_ts.xlsx\", index_col = 0)\n",
    "#obs = pd.read_csv(\"input/observation_ts.csv\")\n",
    "pars = pd.read_csv(\"input/params.csv\", header = 0)\n",
    "pars.columns = ['w', 'n_imperv', 'n_perv', 's_imperv', 's_perv', 'k_sat', 'per_routed', 'cmelt', 'Tb', 'A1', 'B1']\n",
    "#timestamps = pd.read_csv(\"input/timestamps.csv\")\n",
    "OF = pd.read_csv(\"input/OF_values.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Graph Observed and Modeled Output\n",
    "\n",
    "Comprehensive sensitivity analyses require a large number of model runs. This results in overlapping plots often with thousands of time series on them. The overlapping time series of historical and simulation data provides little insight into the frequency of various model output values. The figures below show a time series of the historical data along with a frequency magnitude percentile curve. [Magnitude percentile curves](https://waterprogramming.wordpress.com/2019/02/26/magnitude-varying-sensitivity-analysis-and-visualization-part-1/) allow for interpretation of more and less frequent observation values by grouping the individual time series into percentile ranges. The majority of simulated streamflow values fall below the historical data, implying SWMM tends to underestimate streamflow, especially in higher flow (80th-100th percentile) events. The output plots saves to the \"output/plots/magnitude_perc\" directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load Magnitude_Perc.py\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "# import python libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# back out a directory to load python functions from \"Scripts\" folder\n",
    "org_dir_name = os.path.dirname(os.path.realpath('Magnitude_Perc.py'))\n",
    "parent_dir_name = os.path.dirname(os.path.dirname(os.path.realpath('Magnitude_Perc.py')))\n",
    "os.chdir(parent_dir_name + \"/Scripts\")\n",
    "\n",
    "# load python functions from ‘Scripts’ folder\n",
    "import magnitude_percentile_plots\n",
    "\n",
    "# move back into case study folder\n",
    "os.chdir(org_dir_name)\n",
    "\n",
    "# load in model simulations and observation data\n",
    "sim = pd.read_excel(\"input/simulation_ts.xlsx\", index_col = 0)\n",
    "obs = pd.read_csv(\"input/observation_ts.csv\")\n",
    "\n",
    "# create magnitude percentile plots from observation and simulation time series data\n",
    "magnitude_percentile_plots.magnitude_perc_plots(sim, obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will generate Figure 2 in the JAWRA manuscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jawra_manuscript_figures\n",
    "\n",
    "jawra_manuscript_figures.magnitude_perc_plots_fig2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Approximate Bayesian Computation\n",
    "One method integrated into the workflow was Approximate Bayesian Computation (ABC), which represents the combination of model parameter values that maximize the probability of representing the observed data. ABC applies [Bayesian theory](https://en.wikipedia.org/wiki/Bayes%27_theorem) to parameter spaces to estimate posterior distributions of model parameters. ABC is advantageous because it bypasses calculating the likelihood function by using the model simulations compared to the observed data ([Engeland and Gottschalk 2002](https://www.hydrol-earth-syst-sci.net/6/883/2002/), [Kavetski et al. 2006](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2005WR004368), [Sunnåker et al. 2013](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002803), [Vrugt and Sadegh 2013](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/wrcr.20354)). The steps to compute ABC are: 1) Calculate the observed data’s statistics (e.g. mean, standard deviation) and choose model specific objective functions (e.g. NSE). 2) Assume a uniform sampling interval for the parameter space. Draw a total of n parameters from prior and simulate the model for each of the parameter points, this results in n sequences of simulated data. 3) Calculate objective functions for each sequence of simulated data. 4) Determine the distance between the observed and simulated transition frequencies for all parameter points. Remove parameter points beyond a user specified tolerance interval (e.g. NSE ≥ 0.0) to approximate samples from the posterior distribution. 5) Estimate the posterior distribution with the parameter points within the tolerance interval ([Sunnåker et al. 2013](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002803), [Vrugt and Sadegh 2013](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/wrcr.20354)). \n",
    "\n",
    "For the python script below, specify the number of model runs, tolerance of the objective functions, number of histogram bins and the figure colors. Here we used pre-defined objective functions, but the code can be modified to calculate a variety of objective functions. The plots produced are histograms of the various parameters illustrating the difference between original modeled output and the ABC constrained parameter sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to \"Scripts\" Directory\n",
    "import os\n",
    "og_dir = os.getcwd()\n",
    "root_dir = og_dir[:-4]\n",
    "os.chdir(root_dir+'/Scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load approx_bayes_calc.py\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Created on Mon Jul  8 12:57:45 2019\n",
    "\n",
    "@author: catiefinkenbiner\n",
    "\"\"\"\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''\n",
    "Approximate Baysian Calculation requires:\n",
    "    1) observation dataset (df_obs)\n",
    "    2) parameter sets (df_parms)\n",
    "    3) model output (df_model)\n",
    "    4) objective functions (df_OFs)\n",
    "    5) tolerance\n",
    "    6) number of model runs\n",
    "'''\n",
    "\n",
    "def make_histograms(df_parms,bayes_approx,bins,alpha,cc1,cc2,parameters,metric):\n",
    "    plt.figure(figsize=(12,12))\n",
    "    for col in np.arange(1,((df_parms.iloc[0,:]).size)+1):\n",
    "        plt.subplot(4,4,col)\n",
    "        ax = df_parms.iloc[:,col-1].plot.hist(bins=bins,alpha=alpha,color=cc1,linewidth=4)    \n",
    "        ax = bayes_approx.iloc[:,col-1].plot.hist(bins=bins,alpha=alpha,color=cc2,linewidth=4)\n",
    "        ax.set_xlabel(str(parameters[col-1]))    \n",
    "    plt.legend(['Output','ABC'],fancybox=True)\n",
    "    plt.tight_layout() \n",
    "    plt.savefig('output/plots/ABC/'+metric+'_histogram.png',dpi=1000)\n",
    "\n",
    "def make_cdfs_pdfs(df_parms,bayes_approx,bins,alpha,cc1,cc2,parameters,metric):\n",
    "    plt.figure(figsize=(12,12))\n",
    "    for col in np.arange(1,((df_parms.iloc[0,:]).size)+1):\n",
    "        plt.subplot(4,4,col)\n",
    "        ax = df_parms.iloc[:,col-1].plot.hist(cumulative=True, density=1,bins=bins,alpha=alpha,color=cc1,linewidth=4)    \n",
    "        ax = bayes_approx.iloc[:,col-1].plot.hist(cumulative=True, density=1,bins=bins,alpha=alpha,color=cc2,linewidth=4)\n",
    "        ax.set_xlabel(str(parameters[col-1]))    \n",
    "    plt.legend(['Output','ABC'],fancybox=True)\n",
    "    plt.tight_layout() \n",
    "    plt.savefig('output/plots/ABC/'+metric+'_cdf.png',dpi=1000)\n",
    "    \n",
    "    plt.figure(figsize=(12,12))\n",
    "    for col in np.arange(1,((df_parms.iloc[0,:]).size)+1):\n",
    "        plt.subplot(4,4,col)\n",
    "        ax = df_parms.iloc[:,col-1].plot.kde(alpha=alpha,color=cc1,linewidth=4)    \n",
    "        ax = bayes_approx.iloc[:,col-1].plot.kde(alpha=alpha,color=cc2,linewidth=4)\n",
    "        ax.set_xlabel(str(parameters[col-1]))   \n",
    "    plt.legend(['Output','ABC'],fancybox=True)\n",
    "    plt.tight_layout() \n",
    "    plt.savefig('output/plots/ABC/'+metric+'_pdf.png',dpi=1000)\n",
    "\n",
    "def runABC(df_parms,df_OFs,runs,bins,color1,color2):\n",
    "    # models with objective functions within tolerance thresholds\n",
    "    results = np.array(approx_bayes_calc_OF(df_parms,df_OFs,runs))\n",
    "    \n",
    "    ofs = list(df_OFs.columns.values)\n",
    "    parameters = list(df_parms.columns.values)\n",
    "    \n",
    "    # saves models with objective functions within tolerance thresholds\n",
    "    for i in np.arange(len(results)):\n",
    "        bayes_approx_of = pd.DataFrame(results[i],columns=None)\n",
    "        bayes_approx_of.to_csv('output/bayes_parameters_'+str(ofs[i])+'.csv',index=False)\n",
    "    \n",
    "        # print ABC results and make figures\n",
    "        print('precent of models with '+str(ofs[i])+', tolerance = '+str(tolerances[i])+':',str(len(results[i])/runs),'%')\n",
    "        make_histograms(df_parms,bayes_approx_of,bins,0.5,colors[0],colors[i+1],parameters,ofs[i])\n",
    "        make_cdfs_pdfs(df_parms,bayes_approx_of,bins,0.5,colors[0],colors[i+1],parameters,ofs[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to specify specific tolerances for the user specific objective functions. Please update the code below to fit your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(og_dir)\n",
    "\n",
    "# Specify tolerance for objective functions (OF) - this needs to be updated for user specific applications.\n",
    "# Here we have specified 3 OFs.\n",
    "tolerance_of1 = 6.0   # OF (RMSE) < tolerance\n",
    "tolerance_of2 = 15.0 # -tolerance (p-bias) < OF > tolerance (p-bias)\n",
    "tolerance_of3 = 0.0  # OF >= tolerance (NSE)\n",
    "tolerances = [tolerance_of1,tolerance_of2,tolerance_of3]\n",
    "\n",
    "def approx_bayes_calc_OF(parms,OFs,simulations):\n",
    "    keep_of1 = []; keep_of2 = []; keep_of3 = []\n",
    "    for i in np.arange((simulations)):\n",
    "        # User can redefine tolerances and OF here\n",
    "        if tolerance_of1 < OFs.iloc[i,0]:\n",
    "            keep_of1.append(parms.loc[i])\n",
    "            \n",
    "        if tolerance_of2 > np.absolute(OFs.iloc[i,1]):\n",
    "            keep_of2.append(parms.loc[i])\n",
    "            \n",
    "        if tolerance_of3 <= OFs.iloc[i,2] :\n",
    "            keep_of3.append(parms.loc[i])        \n",
    "\n",
    "    return keep_of1,keep_of2,keep_of3\n",
    "\n",
    "runs = 24000 # specify number of model runs\n",
    "bins = 100   # specify number of histogram bins\n",
    "color1 = 'b' # color of original model output\n",
    "color2 = 'k' # color of 1st ABC applied to OF (RMSE)\n",
    "color3 = 'r' # color of 2nd ABC applied to OF (p-bias)\n",
    "color4 = 'g' # color of 3rd ABC applied to OF (NSE)\n",
    "colors = [color1,color2,color3,color4]\n",
    "\n",
    "# Runs function that evaluates models outputs with approximate Bayesian computation\n",
    "runABC(pars, OF.iloc[:,3:], runs, bins, color1, color2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will generate Figure 3 in the JAWRA manuscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jawra_manuscript_figures\n",
    "\n",
    "jawra_manuscript_figures.ABC_plots_fig3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Sensitivity Analysis\n",
    "Three sensitivity analyses are incorporated into the workflow: a variance-based sensitivity analysis, a moment-independent sensitivity analysis, and an ordinary least squares regression. The Sobol method ([Sobol, 2001](https://doi.org/10.1016/S0378-4754(00)00270-6)) is a variance-based global sensitivity analysis that yielded first-order, second-order, and total-order sensitivity indices. Sobol’s method can effectively handle nonlinear responses and measures the effects of interactions within non-additive systems. It decomposes the variance of the model output into fractions which can be attributed to inputs or sets of inputs. The first-order sensitivity index (i.e. main effect index) quantifies parameter impact on model output variance by averaging over the variations in other input parameters. The second-order sensitivity index decomposes model variance by parameter interactions with one another. The total-order sensitivity index (i.e. total effect index) measures the contribution each parameter had on model output across the first-order index and all higher-order indices. Our workflow employs the Saltelli scheme ([Saltelli, 2002](https://doi.org/10.1016/S0010-4655(02)00280-1); [Saltelli et al., 2010](https://doi.org/10.1016/j.cpc.2009.09.018)), which allows for the calculation of the first-order, second-order, and total-order sensitivity indices with fewer model runs than a traditional approach. However, since the calculation of Sobol second-order indices requires N * (2K + 2) model runs (where N is preset model runs and K is number of parameters), some models may be too computationally expensive to run with multiple input parameters. Consequently, we included two additional sensitivity analyses which have no minimum number of model runs.\n",
    "\n",
    "The Delta index ([Borgonovo, 2007](https://doi.org/10.1016/j.ress.2006.04.015); [Borgonovo et al., 2012](https://www.sciencedirect.com/science/article/pii/S1364815211001617?via%3Dihub); [Plischke et al., 2013](https://doi.org/10.1016/j.ejor.2012.11.047)) is a moment-independent global sensitivity analysis. While less robust than indices returned by a variance-based sensitivity analysis, a moment-independent sensitivity analysis was a popular technique due to its computational efficiency and insensitivity to dependent parameters ([Pannell, 1997](https://doi.org/10.1016/S0169-5150(96)01217-0)). The Delta sensitivity analysis searches for parameters with the greatest impact on the probability density function of model output. Delta indices capture non-linear and non-monotonic parameter-output dynamics. Lastly, the ordinary least squares (OLS) regression yields an R2 coefficient, which quantified the linear effects of model input parameters on model output variance. OLS regressions have long been employed throughout model sensitivity analyses and assume an explicit interaction between model output and any given parameter ([Kleijnen, 1995](https://doi.org/10.1002/sdr.4260110403); [Pannell, 1997](https://doi.org/10.1016/S0169-5150(96)01217-0); [Zobitz et al., 2006](https://doi.org/10.1016/j.agrformet.2006.01.003)).\n",
    "\n",
    "To visualize objective function sensitivity to model input parameters, the following code produces radial convergence plots, scatter plots, portrait plots, and spider plots based on the outputs from the sensitivity analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sobol and delta sensitivity indices are calculated using a modified version of the Python sensitivity analysis library ([SALib](https://salib.readthedocs.io/en/latest/index.html)) and the OLS regression is calculated using [StatsModels](https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLS.html) library in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load SensIndices_RCPlots.py\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "# import python libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# back out a directory to load python functions from \"Scripts\" folder\n",
    "org_dir_name = os.path.dirname(os.path.realpath('SensIndices_RCPlots.py'))\n",
    "parent_dir_name = os.path.dirname(os.path.dirname(os.path.realpath('SensIndices_RCPlots.py')))\n",
    "os.chdir(parent_dir_name + \"/Scripts\")\n",
    "\n",
    "# load python functions from ‘Scripts’ folder\n",
    "import delta\n",
    "import sobol\n",
    "import ols\n",
    "import radial_conv_plots\n",
    "\n",
    "# move back into case study 0 folder\n",
    "os.chdir(org_dir_name)\n",
    "\n",
    "# Define the model inputs\n",
    "problem = {\n",
    "    'num_vars': 11,\n",
    "    'names': ['w', 'n_imperv', 'n_perv', 's_imperv', 's_perv', 'k_sat', 'per_routed', 'cmelt', 'Tb', 'A1', 'B1'],\n",
    "    'bounds': [[500, 1500], # meters\n",
    "               [0.01, 0.2],\n",
    "               [0.01, 0.2],\n",
    "               [0, 10],\n",
    "               [0, 10],\n",
    "               [0.01, 10],\n",
    "               [0, 100],\n",
    "               [0, 4],\n",
    "               [-3, 3],\n",
    "               [0.0001, 0.01],\n",
    "               [1, 3]]\n",
    "}\n",
    "\n",
    "# load in model parameter sets (Saltelli sampled) and objective function values\n",
    "pars = pd.read_csv(\"input/params.csv\", header = 0)\n",
    "OF = pd.read_csv(\"input/OF_values.csv\")\n",
    "\n",
    "# save the parameter names\n",
    "param_names = problem['names']\n",
    "\n",
    "# calculate Sobol first-, second-, and total order indices --> MUST BE BASED ON SALTELLI SAMPLING SCHEME\n",
    "results_SI = []\n",
    "results_SI = sobol.objective_function_sobol(problem, OF)\n",
    "\n",
    "# create radial convergence plots based on results_SI\n",
    "radial_conv_plots.radial_conv_plots(problem, results_SI, OF)\n",
    "\n",
    "# calculate delta indices and sobol first-order indices\n",
    "results_delta = []\n",
    "results_delta = delta.objective_function_delta(problem, pars, OF)\n",
    "\n",
    "# calculate R^2 from OLS regression\n",
    "results_R2 = []\n",
    "results_R2 = ols.objective_function_OLS(OF, pars, param_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the sensitivity analysis results (calculated and exported from python), we can create portrait plots, scatter plots, and spider plots for various objective functions and parameter values.\n",
    "\n",
    "First, the data is loaded and formatted into a usable format and then exported to a .csv file. Then the script creates additional plots to help visualize and convey parameter sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RParsingError",
     "evalue": "R parsing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRParsingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1c125b89501d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'R'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'# %load Portrait_Scatter_Spider.R\\n\\nlibrary(dplyr)\\n\\n# load in objective function values and parameter sets\\npars <- read.csv(\"input/params.csv\", header = TRUE)\\n  # \"model_runs\" rows, \"num_pars\" columns\\n\\nOF <- read.csv(\"input/OF_values.csv\", header = TRUE)\\n  # \"model_runs\" rows, \"num_OF\" columns\\n\\n# save names of objective functions and parameters\\nOF_names <- colnames(OF)\\nparam_names <- colnames(pars)\\n\\n# set variables of number of model runs, time steps, and number of parameters\\nmodel_runs <- nrow(pars)\\nnum_pars <- ncol(pars)\\nnum_OF <- ncol(OF)\\n\\n# load in results from delta, sobol, and ols sensitivity analyses (calculated in python script)\\nsource(\"../Scripts/python_to_r_results.R\")\\nresults_sobol <- python_to_r_results(data_type = \"sobol\", param_names, OF_names)\\nresults_delta <- python_to_r_results(data_type = \"delta\", param_names, OF_names)\\nresults_ols <- python_to_r_results(data_type = \"ols\", param_names, OF_names)\\n\\n\\'\\'\\'\\n# save as csv files\\nlapply(results_sobol, function(x) write.table(data.frame(x), \\'output/formatted_sobol.csv\\', append = T, sep = \\',\\' ))\\nlapply(results_delta, function(x) write.table(data.frame(x), \\'output/formatted_delta.csv\\', append = T, sep = \\',\\' ))\\nlapply(results_ols, function(x) write.table(data.frame(x), \\'output/formatted_ols.csv\\', append = T, sep = \\',\\' ))\\n\\n# scatter plots of objective functions versus parameter values\\nsource(\"../Scripts/scatterplots.R\")\\nfor (i in 1:num_OF) {\\n  \\n  # subset by objective function, i\\n  objective_fun <- OF[, i]\\n\\n  # create scatterplots of all parameters versus objective function, i\\n  par_OF_scatter(params = pars, objective_fun, OF_name = colnames(OF)[i])\\n  \\n}\\n\\n# portrait plots of objective functions versus parameter values\\nsource(\"../Scripts/portrait_plots.R\")\\nportrait_plot(results_sobol, \"sobol\")\\nportrait_plot(results_delta, \"delta\")\\nportrait_plot(results_ols, \"ols\")\\n\\'\\'\\'\\n\\n# spiders plots of objective functions versus parameter values\\nsource(\"../Scripts/spider_plots.R\")\\nspiderplot(results_sobol)\\nspiderplot(results_delta)\\nspiderplot(results_ols)\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/si_py/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2350\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2352\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2353\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</Users/catiefinkenbiner/.conda/envs/si_py/lib/python3.6/site-packages/decorator.py:decorator-gen-130>\u001b[0m in \u001b[0;36mR\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/si_py/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/si_py/lib/python3.6/site-packages/rpy2/ipython/rmagic.py\u001b[0m in \u001b[0;36mR\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m    736\u001b[0m                     \u001b[0mreturn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m                 \u001b[0mtext_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisible\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m                 \u001b[0mtext_output\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtext_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mvisible\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/si_py/lib/python3.6/site-packages/rpy2/ipython/rmagic.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m                 \u001b[0;31m# Need the newline in case the last line in code is a comment.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m                 \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisible\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"withVisible({%s\\n})\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRRuntimeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0;31m# Otherwise next return seems to have copy of error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/si_py/lib/python3.6/site-packages/rpy2/robjects/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrinterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpy2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/si_py/lib/python3.6/site-packages/rpy2/rinterface_lib/conversion.py\u001b[0m in \u001b[0;36m_\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_cdata_res_to_rinterface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mcdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;31m# TODO: test cdata is of the expected CType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_cdata_to_rinterface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/si_py/lib/python3.6/site-packages/rpy2/rinterface.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(text, num)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text must be a string.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mrobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStrSexpVector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_rinterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sexp__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/si_py/lib/python3.6/site-packages/rpy2/rinterface_lib/_rinterface_capi.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(cdata, num)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mrlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPARSE_OK\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0mrlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRf_unprotect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRParsingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'R parsing'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPARSING_STATUS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m     \u001b[0mrlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRf_unprotect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRParsingError\u001b[0m: R parsing"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "# %load Portrait_Scatter_Spider.R\n",
    "\n",
    "library(dplyr)\n",
    "\n",
    "# load in objective function values and parameter sets\n",
    "pars <- read.csv(\"input/params.csv\", header = TRUE)\n",
    "  # \"model_runs\" rows, \"num_pars\" columns\n",
    "\n",
    "OF <- read.csv(\"input/OF_values.csv\", header = TRUE)\n",
    "  # \"model_runs\" rows, \"num_OF\" columns\n",
    "\n",
    "# save names of objective functions and parameters\n",
    "OF_names <- colnames(OF)\n",
    "param_names <- colnames(pars)\n",
    "\n",
    "# set variables of number of model runs, time steps, and number of parameters\n",
    "model_runs <- nrow(pars)\n",
    "num_pars <- ncol(pars)\n",
    "num_OF <- ncol(OF)\n",
    "\n",
    "# load in results from delta, sobol, and ols sensitivity analyses (calculated in python script)\n",
    "source(\"../Scripts/python_to_r_results.R\")\n",
    "results_sobol <- python_to_r_results(data_type = \"sobol\", param_names, OF_names)\n",
    "results_delta <- python_to_r_results(data_type = \"delta\", param_names, OF_names)\n",
    "results_ols <- python_to_r_results(data_type = \"ols\", param_names, OF_names)\n",
    "\n",
    "# save as csv files\n",
    "lapply(results_sobol, function(x) write.table(data.frame(x), 'output/formatted_sobol.csv', append = T, sep = ',' ))\n",
    "lapply(results_delta, function(x) write.table(data.frame(x), 'output/formatted_delta.csv', append = T, sep = ',' ))\n",
    "lapply(results_ols, function(x) write.table(data.frame(x), 'output/formatted_ols.csv', append = T, sep = ',' ))\n",
    "\n",
    "# scatter plots of objective functions versus parameter values\n",
    "source(\"../Scripts/scatterplots.R\")\n",
    "for (i in 1:num_OF) {\n",
    "  \n",
    "  # subset by objective function, i\n",
    "  objective_fun <- OF[, i]\n",
    "\n",
    "  # create scatterplots of all parameters versus objective function, i\n",
    "  par_OF_scatter(params = pars, objective_fun, OF_name = colnames(OF)[i])\n",
    "  \n",
    "}\n",
    "\n",
    "# portrait plots of objective functions versus parameter values\n",
    "source(\"../Scripts/portrait_plots.R\")\n",
    "portrait_plot(results_sobol, \"sobol\")\n",
    "portrait_plot(results_delta, \"delta\")\n",
    "portrait_plot(results_ols, \"ols\")\n",
    "\n",
    "# spiders plots of objective functions versus parameter values\n",
    "source(\"../Scripts/spider_plots.R\")\n",
    "spiderplot(results_sobol)\n",
    "spiderplot(results_delta)\n",
    "spiderplot(results_ols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Inference of Results\n",
    "\n",
    "ABC was implemented with a tolerance specified at NSE ≥ 0.0 and the results from the workflow were visualized as histograms, CDFs and pdfs. The histograms illustrate the frequency distributions of parameter sets constrained by ABC specified tolerances (Figure 3(a)). Changing the tolerance will adjust the frequency distributions of parameters as a function of the user specified objective functions. CDFs (refer to GitHub repository) and pdfs (Figure 3(b)) provide the user with additional visualizations of the constrained parameter sets based on ABC. Based on Figure 3, the SWMM model configurations with the most positive NSE values have the A1 parameter equaling values near zero. One might conclude the A1 parameter should be sampled from a constrained range of values, skewed toward zero. Constraining A1 may adjust the histograms, CDFs and pdfs of other parameters depending on the user specified objective function and tolerance interval. However, it is impossible to conclude this without understanding the relationships and dependencies between the various parameters of the model. Additional sensitivity analyses are required to adequately describe the parameter interactions within hydrologic models.\n",
    "\n",
    "The scatterplots of objective function value versus parameter value illustrate a linear relationship indicated by the R2 value from the OLS sensitivity analysis. For Cast Study 0, it can be inferred that the A1 and B1 groundwater coefficients have the strongest linear impacts on the objective function (i.e. NSE). The spider plots illustrate the difference in sensitivity index magnitudes across the model parameters for each objective function and sensitivity analysis. The results reinforce the OLS regression results of the A1 and B1 groundwater coefficients being the most impactful on model output.\n",
    "\n",
    "The radial convergence plots (RCPs) were produced as a result of the Sobol sensitivity analysis. RCPs visualize not only the first-order and total-order sensitivity for each parameter but also the second-order interactions between model parameters. Large first-order indices indicate the parameter is influential over model output or the objective function. Small first-order indices indicate the parameter is unimportant in model output, which allows for model simplification. Second-order indices describe how much the interactions between two parameters influence model output, and total-order indices describe how much the sum of all parameter interactions influence model output.\n",
    "\n",
    "The next visuals produced by the workflow are portrait plots. Portrait plots allow for the direct comparison of all objective functions and parameters for each sensitivity analysis. In the plots below, a darker shade of green indicates higher objective function sensitivity to model parameter value. While several parameters seem to have a linear impact on the objective functions in the OLS regression, for the Sobol and Delta sensitivity analyses, the A1 and B1 groundwater parameters show the most significant influence over the various objective function values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Conclusions\n",
    "\n",
    "The workflow is organized modularly to incorporate additional sensitivity analyses and visualization techniques. Future work could further develop the process to allow for the iteration of parameter sampling based on the results of the various sensitivity analyses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
