{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 1: Hydrologic models of soil physical processes from the NWM and TOPMODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sleepers River Research Watershed (SRRW) in Vermont is an active hydrologic research site since 1959 and was the setting where Dunne and Black (1970) determined the controls of saturation-excess overland flow (SOF) on streamflow generation.\n",
    "\n",
    "This jupyter notebook has code cells to:\n",
    "1. Load data for use in R and Python scripts\n",
    "2. Create a historical time series and magnitude percentile plots for simulated data\n",
    "3. Generate a priori and a posteriori parameter distribution plots via Approximate Bayesian Computation\n",
    "4. Compute Sobol first-order, delta, and OLS sensitivity indices\n",
    "5. Produce portrait, scatter, and spider plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete and visualize a comprehensive sensitivity analysis on the SWMM simulations, we use packages from both R and Python. This command allows us to run R scripts in the Python jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the model simulation data, observation/truth data, parameter sets, time stamps, and objective function values into Python as data frames using the pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sim = pd.read_csv(\"input/simulation_ts.csv\", index_col = 0)\n",
    "pars = pd.read_csv(\"input/params.csv\", header = 0)\n",
    "OF = pd.read_csv(\"input/OF_values.csv\")\n",
    "obs = pd.read_csv(\"input/observation_ts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Approximate Bayesian Computation\n",
    "One method integrated into the workflow was Approximate Bayesian Computation (ABC), which represents the combination of model parameter values that maximize the probability of representing the observed data. ABC applies [Bayesian theory](https://en.wikipedia.org/wiki/Bayes%27_theorem) to parameter spaces to estimate posterior distributions of model parameters. ABC is advantageous because it bypasses calculating the likelihood function by using the model simulations compared to the observed data ([Engeland and Gottschalk 2002](https://www.hydrol-earth-syst-sci.net/6/883/2002/), [Kavetski et al. 2006](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2005WR004368), [Sunnåker et al. 2013](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002803), [Vrugt and Sadegh 2013](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/wrcr.20354)). The steps to compute ABC are: 1) Calculate the observed data’s statistics (e.g. mean, standard deviation) and choose model specific objective functions (e.g. NSE). 2) Assume a uniform sampling interval for the parameter space. Draw a total of n parameters from prior and simulate the model for each of the parameter points, this results in n sequences of simulated data. 3) Calculate objective functions for each sequence of simulated data. 4) Determine the distance between the observed and simulated transition frequencies for all parameter points. Remove parameter points beyond a user specified tolerance interval (e.g. NSE ≥ 0.0) to approximate samples from the posterior distribution. 5) Estimate the posterior distribution with the parameter points within the tolerance interval ([Sunnåker et al. 2013](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002803), [Vrugt and Sadegh 2013](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/wrcr.20354)). \n",
    "\n",
    "For the python script below, specify the number of model runs, tolerance of the objective functions, number of histogram bins and the figure colors. Here we used pre-defined objective functions, but the code can be modified to calculate a variety of objective functions. The plots produced are histograms of the various parameters illustrating the difference between original modeled output and the ABC constrained parameter sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load approx_bayes_calc_of_defined.py \n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "'''\n",
    "Approximate Baysian Calculation requires:\n",
    "    1) observation dataset (df_obs)\n",
    "    2) parameter sets (df_parms)\n",
    "    3) model output (df_model)\n",
    "    4) objective functions (df_OFs)\n",
    "    5) tolerance\n",
    "    6) number of model runs\n",
    "'''\n",
    "\n",
    "def approx_bayes_calc_OF(parms,OFs,simulations):\n",
    "    keep_nse = []\n",
    "    for i in np.arange(simulations):\n",
    "        # User can redefine tolerance and OF here\n",
    "        if OFs.iloc[i,0] >= tolerance_nse:\n",
    "            keep_nse.append(parms.iloc[i])        \n",
    "    return keep_nse\n",
    "\n",
    "def make_histograms(df_parms,bayes_approx,bins,alpha,cc1,cc2,parameters,metric):\n",
    "    plt.figure(figsize=(15,12))\n",
    "    gridsize = math.ceil((np.sqrt((df_parms.iloc[0,:]).size))) # graph columns\n",
    "    \n",
    "    for col in np.arange(1,((df_parms.iloc[0,:]).size)+1):\n",
    "        plt.subplot(gridsize-1,gridsize,col)\n",
    "        ax = df_parms.iloc[:,col-1].plot.hist(bins=bins,alpha=alpha,color=cc1,linewidth=4)    \n",
    "        ax = bayes_approx.iloc[:,col-1].plot.hist(bins=bins,alpha=alpha,color=cc2,linewidth=4)\n",
    "        ax.set_xlabel(str(parameters[col-1]))    \n",
    "    plt.legend(['Output','ABC'],fancybox=True)\n",
    "    plt.tight_layout() \n",
    "    plt.savefig('output/plots/ABC/'+metric+'_histogram.png',dpi=1000)\n",
    "\n",
    "def make_cdfs_pdfs(df_parms,bayes_approx,bins,alpha,cc1,cc2,parameters,metric):\n",
    "    plt.figure(figsize=(15,12))\n",
    "    gridsize = math.ceil((np.sqrt((df_parms.iloc[0,:]).size)))\n",
    "    \n",
    "    for col in np.arange(1,((df_parms.iloc[0,:]).size)+1):\n",
    "        plt.subplot(gridsize-1,gridsize,col)\n",
    "        ax = df_parms.iloc[:,col-1].plot.hist(cumulative=True, density=1,bins=bins,alpha=alpha,color=cc1,linewidth=4)    \n",
    "        ax = bayes_approx.iloc[:,col-1].plot.hist(cumulative=True, density=1,bins=bins,alpha=alpha,color=cc2,linewidth=4)\n",
    "        ax.set_xlabel(str(parameters[col-1]))    \n",
    "    plt.legend(['Output','ABC'],fancybox=True)\n",
    "    plt.tight_layout() \n",
    "    plt.savefig('output/plots/ABC/'+metric+'_cdf.png',dpi=1000)\n",
    "    \n",
    "    plt.figure(figsize=(15,12))\n",
    "    gridsize = math.ceil((np.sqrt((df_parms.iloc[0,:]).size)))\n",
    "    \n",
    "    for col in np.arange(1,((df_parms.iloc[0,:]).size)+1):\n",
    "        plt.subplot(gridsize-1,gridsize,col)\n",
    "        ax = df_parms.iloc[:,col-1].plot.kde(alpha=alpha,color=cc1,linewidth=4)    \n",
    "        ax = bayes_approx.iloc[:,col-1].plot.kde(alpha=alpha,color=cc2,linewidth=4)\n",
    "        ax.set_xlabel(str(parameters[col-1]))   \n",
    "    plt.legend(['Output','ABC'],fancybox=True)\n",
    "    plt.tight_layout() \n",
    "    plt.savefig('output/plots/ABC/'+metric+'_pdf.png',dpi=1000)\n",
    "\n",
    "def runABC(df_parms,df_OFs,runs,bins,color1,color2):\n",
    "    # models with objective functions within tolerance thresholds\n",
    "    results_nse = np.array(approx_bayes_calc_OF(df_parms,df_OFs,runs))\n",
    "\n",
    "    # saves models with objective functions within tolerance thresholds\n",
    "    bayes_approx_nse = pd.DataFrame(results_nse,columns=None)\n",
    "    bayes_approx_nse.to_csv('output/bayes_parameters_NSE.csv',index=False)\n",
    "    parameters = list(df_parms.columns.values)\n",
    "    \n",
    "    # print ABC results and make figures\n",
    "    print('precent of models with NSE >= to',str(tolerance_nse),'are:',str(len(results_nse)/runs),'%')\n",
    "    make_histograms(df_parms,bayes_approx_nse,bins,0.5,color1,color2,parameters,'NSE')\n",
    "    make_cdfs_pdfs(df_parms,bayes_approx_nse,bins,0.5,color1,color2,parameters,'NSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify tolerance for objective functions (OF)\n",
    "tolerance_nse = 0.0  # OF >= tolerance (NSE)\n",
    "\n",
    "runs = 5000 # specify number of model runs\n",
    "bins = 100   # specify number of histogram bins\n",
    "color1 = 'b' # color of original model output\n",
    "color2 = 'k' # color of 1st ABC applied to OF (NSE)\n",
    "\n",
    "# Runs function that evaluates models outputs with approximate Bayesian computation\n",
    "runABC(pars, OF, runs, bins, color1, color2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Sensitivity Analysis\n",
    "Two sensitivity analyses are incorporated into the workflow: a moment-independent sensitivity analysis and an ordinary least squares regression.\n",
    "\n",
    "The Delta index ([Borgonovo, 2007](https://doi.org/10.1016/j.ress.2006.04.015); [Borgonovo et al., 2012](https://www.sciencedirect.com/science/article/pii/S1364815211001617?via%3Dihub); [Plischke et al., 2013](https://doi.org/10.1016/j.ejor.2012.11.047)) is a moment-independent global sensitivity analysis. While less robust than indices returned by a variance-based sensitivity analysis, a moment-independent sensitivity analysis was a popular technique due to its computational efficiency and insensitivity to dependent parameters ([Pannell, 1997](https://doi.org/10.1016/S0169-5150(96)01217-0)). The Delta sensitivity analysis searches for parameters with the greatest impact on the probability density function of model output. Delta indices capture non-linear and non-monotonic parameter-output dynamics. Lastly, the ordinary least squares (OLS) regression yields an R2 coefficient, which quantified the linear effects of model input parameters on model output variance. OLS regressions have long been employed throughout model sensitivity analyses and assume an explicit interaction between model output and any given parameter ([Kleijnen, 1995](https://doi.org/10.1002/sdr.4260110403); [Pannell, 1997](https://doi.org/10.1016/S0169-5150(96)01217-0); [Zobitz et al., 2006](https://doi.org/10.1016/j.agrformet.2006.01.003)).\n",
    "\n",
    "To visualize objective function sensitivity to model input parameters, the following code produces radial convergence plots, scatter plots, portrait plots, and spider plots based on the outputs from the sensitivity analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sobol and delta sensitivity indices are calculated using a modified version of the Python sensitivity analysis library ([SALib](https://salib.readthedocs.io/en/latest/index.html)) and the OLS regression is calculated using [StatsModels](https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLS.html) library in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load SensIndices_RCPlots.py\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "# import python libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# back out a directory to load python functions from \"Scripts\" folder\n",
    "org_dir_name = os.path.dirname(os.path.realpath('SensIndices_RCPlots.py'))\n",
    "parent_dir_name = os.path.dirname(os.path.dirname(os.path.realpath('SensIndices_RCPlots.py')))\n",
    "os.chdir(parent_dir_name + \"/Scripts\")\n",
    "\n",
    "# load python functions from ‘Scripts’ folder\n",
    "import delta\n",
    "import ols\n",
    "\n",
    "# move back into case study 0 folder\n",
    "os.chdir(org_dir_name)\n",
    "\n",
    "# load in model parameters and OF values\n",
    "pars = pd.read_csv(\"input/params.csv\", index_col = 0)\n",
    "OF = pd.read_csv(\"input/OF_values.csv\")\n",
    "\n",
    "# Define the model inputs\n",
    "problem = {\n",
    "    'num_vars': 10,\n",
    "    'names': ['qs0', 'lnTe', 'm', 'Sr0', 'Srmax', 'td', 'vch', 'vr', 'k0', 'CD']\n",
    "\n",
    "}\n",
    "\n",
    "# save the parameter names\n",
    "param_names = problem['names']\n",
    "\n",
    "# calculate delta indices and sobol first-order indices\n",
    "results_delta = []\n",
    "results_delta = delta.objective_function_delta(problem, pars, OF)\n",
    "\n",
    "# calculate R^2 from OLS regression\n",
    "results_R2 = []\n",
    "results_R2 = ols.objective_function_OLS(OF, pars, param_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the sensitivity analysis results (calculated and exported from python), we can create portrait plots, scatter plots, and spider plots for various objective functions and parameter values.\n",
    "\n",
    "First, the data is loaded and formatted into a usable format and then exported to a .csv file. Then the script creates additional plots to help visualize and convey parameter sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# %load Portrait_Scatter_Spider.R\n",
    "# This script loads in data from Sobol, Delta, and OLS sensitivity analyses calculated in\n",
    "# Python script for Case Study 0: Fall Creek, NY.\n",
    "\n",
    "library(dplyr)\n",
    "\n",
    "# load in parameter sets, objective functions, observation, simulation, and time steps\n",
    "pars <- read.csv(\"input/params.csv\", header = TRUE) %>%\n",
    "  dplyr::select(-1)\n",
    "  # \"model_runs\" rows, \"num_pars\" columns\n",
    "\n",
    "OF <- read.csv(\"input/OF_values.csv\", header = TRUE)\n",
    "  # \"model_runs\" rows, \"num_OF\" columns\n",
    "\n",
    "# save names of objective functions and parameters\n",
    "OF_names <- colnames(OF)\n",
    "param_names <- colnames(pars)\n",
    "\n",
    "# set variables of number of model runs, time steps, and number of parameters\n",
    "model_runs <- nrow(pars)\n",
    "num_pars <- ncol(pars)\n",
    "num_OF <- ncol(OF)\n",
    "\n",
    "# load in results from delta, sobol, and ols sensitivity analyses (calculated in python script)\n",
    "source(\"../Scripts/python_to_r_results.R\")\n",
    "results_delta <- python_to_r_results(data_type = \"delta\", param_names, OF_names)\n",
    "results_ols <- python_to_r_results(data_type = \"ols\", param_names, OF_names)\n",
    "\n",
    "# save as csv files\n",
    "lapply(results_delta, function(x) write.table(data.frame(x), 'output/formatted_delta.csv', append = T, sep = ',' ))\n",
    "lapply(results_ols, function(x) write.table(data.frame(x), 'output/formatted_ols.csv', append = T, sep = ',' ))\n",
    "\n",
    "# scatter plots of objective functions versus parameter values\n",
    "source(\"../Scripts/scatterplots.R\")\n",
    "for (i in 1:num_OF) {\n",
    "  \n",
    "  # subset by objective function, i\n",
    "  objective_fun <- OF[, i]\n",
    "  \n",
    "  # create scatterplots of all parameters versus objective function, i\n",
    "  par_OF_scatter(params = pars, objective_fun, OF_name = colnames(OF)[i])\n",
    "  \n",
    "}\n",
    "\n",
    "# portrait plots of objective functions versus parameter values\n",
    "source(\"../Scripts/portrait_plots.R\")\n",
    "portrait_plot(results_delta, \"delta\")\n",
    "portrait_plot(results_ols, \"ols\")\n",
    "\n",
    "# spiders plots of objective functions versus parameter values\n",
    "source(\"../Scripts/spider_plots.R\")\n",
    "spiderplot(results_delta)\n",
    "spiderplot(results_ols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
